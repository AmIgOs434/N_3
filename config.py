"""
–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AI Clip Creator —Å —Å–∏—Å—Ç–µ–º–æ–π —É—Ä–æ–≤–Ω–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""

import os
from dataclasses import dataclass
from enum import IntEnum
from pathlib import Path
from typing import Optional


class PerformanceLevel(IntEnum):
    """–£—Ä–æ–≤–Ω–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (1 = –º–∏–Ω–∏–º—É–º, 5 = –º–∞–∫—Å–∏–º—É–º)"""
    MINIMAL = 1      # –°–ª–∞–±—ã–π CPU, –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
    LOW = 2          # –°—Ä–µ–¥–Ω–∏–π CPU, –±–∞–∑–æ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
    MEDIUM = 3       # –•–æ—Ä–æ—à–∏–π CPU –∏–ª–∏ —Å–ª–∞–±—ã–π GPU, —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
    HIGH = 4         # –ú–æ—â–Ω—ã–π CPU –∏–ª–∏ —Å—Ä–µ–¥–Ω–∏–π GPU, –æ—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
    ULTRA = 5        # –¢–æ–ø–æ–≤—ã–π GPU, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ


@dataclass
class PerformanceConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    # Whisper –º–æ–¥–µ–ª—å
    whisper_model: str
    
    # YOLO –º–æ–¥–µ–ª—å
    yolo_model: str
    yolo_confidence: float
    
    # –ß–∞—Å—Ç–æ—Ç–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏
    detect_every_n_frames: int
    
    # –ê–Ω–∞–ª–∏–∑
    enable_ai_analysis: bool
    enable_scene_detection: bool
    enable_audio_analysis: bool
    enable_visual_analysis: bool
    
    # –ö–∞—á–µ—Å—Ç–≤–æ –≤—ã–≤–æ–¥–∞
    output_bitrate: str
    output_fps: int
    
    # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
    max_segments: int
    min_segment_duration: float
    max_segment_duration: float
    
    # GPU
    use_gpu: bool
    fp16: bool  # Mixed precision –¥–ª—è GPU
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
    batch_size: int
    num_workers: int


# –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—Ä–æ–≤–Ω—è
PERFORMANCE_PRESETS = {
    PerformanceLevel.MINIMAL: PerformanceConfig(
        whisper_model="tiny",
        yolo_model="yolov8n.pt",
        yolo_confidence=0.4,
        detect_every_n_frames=10,
        enable_ai_analysis=False,
        enable_scene_detection=False,
        enable_audio_analysis=False,
        enable_visual_analysis=False,
        output_bitrate="4M",
        output_fps=24,
        max_segments=3,
        min_segment_duration=17.0,  # –•–ê–†–î–ö–û–î: 17 —Å–µ–∫—É–Ω–¥
        max_segment_duration=60.0,  # –•–ê–†–î–ö–û–î: 60 —Å–µ–∫—É–Ω–¥
        use_gpu=False,
        fp16=False,
        batch_size=1,
        num_workers=2,
    ),
    
    PerformanceLevel.LOW: PerformanceConfig(
        whisper_model="base",
        yolo_model="yolov8n.pt",
        yolo_confidence=0.4,
        detect_every_n_frames=5,
        enable_ai_analysis=False,
        enable_scene_detection=True,
        enable_audio_analysis=False,
        enable_visual_analysis=False,
        output_bitrate="6M",
        output_fps=30,
        max_segments=5,
        min_segment_duration=17.0,  # –•–ê–†–î–ö–û–î: 17 —Å–µ–∫—É–Ω–¥
        max_segment_duration=60.0,  # –•–ê–†–î–ö–û–î: 60 —Å–µ–∫—É–Ω–¥
        use_gpu=False,
        fp16=False,
        batch_size=1,
        num_workers=2,
    ),
    
    PerformanceLevel.MEDIUM: PerformanceConfig(
        whisper_model="small",
        yolo_model="yolov8s.pt",
        yolo_confidence=0.35,
        detect_every_n_frames=3,
        enable_ai_analysis=True,
        enable_scene_detection=True,
        enable_audio_analysis=True,
        enable_visual_analysis=False,
        output_bitrate="8M",
        output_fps=30,
        max_segments=8,
        min_segment_duration=17.0,  # –•–ê–†–î–ö–û–î: 17 —Å–µ–∫—É–Ω–¥
        max_segment_duration=60.0,  # –•–ê–†–î–ö–û–î: 60 —Å–µ–∫—É–Ω–¥
        use_gpu=True,
        fp16=True,
        batch_size=2,
        num_workers=4,
    ),
    
    PerformanceLevel.HIGH: PerformanceConfig(
        whisper_model="medium",
        yolo_model="yolov8m.pt",
        yolo_confidence=0.3,
        detect_every_n_frames=2,
        enable_ai_analysis=True,
        enable_scene_detection=True,
        enable_audio_analysis=True,
        enable_visual_analysis=True,
        output_bitrate="10M",
        output_fps=30,
        max_segments=10,
        min_segment_duration=17.0,  # –•–ê–†–î–ö–û–î: 17 —Å–µ–∫—É–Ω–¥
        max_segment_duration=60.0,  # –•–ê–†–î–ö–û–î: 60 —Å–µ–∫—É–Ω–¥
        use_gpu=True,
        fp16=True,
        batch_size=4,
        num_workers=4,
    ),
    
    PerformanceLevel.ULTRA: PerformanceConfig(
        whisper_model="large-v2",
        yolo_model="yolov8x.pt",
        yolo_confidence=0.25,
        detect_every_n_frames=1,
        enable_ai_analysis=True,
        enable_scene_detection=True,
        enable_audio_analysis=True,
        enable_visual_analysis=True,
        output_bitrate="15M",
        output_fps=30,
        max_segments=15,
        min_segment_duration=17.0,  # –•–ê–†–î–ö–û–î: 17 —Å–µ–∫—É–Ω–¥
        max_segment_duration=60.0,  # –•–ê–†–î–ö–û–î: 60 —Å–µ–∫—É–Ω–¥
        use_gpu=True,
        fp16=True,
        batch_size=8,
        num_workers=8,
    ),
}


def detect_environment() -> dict:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞"""
    is_colab = 'COLAB_GPU' in os.environ or Path('/content').exists()
    
    has_gpu = False
    gpu_name = None
    gpu_memory_gb = 0
    
    try:
        import torch
        if torch.cuda.is_available():
            has_gpu = True
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
    except:
        pass
    
    import multiprocessing
    cpu_count = multiprocessing.cpu_count()
    
    return {
        'is_colab': is_colab,
        'has_gpu': has_gpu,
        'gpu_name': gpu_name,
        'gpu_memory_gb': gpu_memory_gb,
        'cpu_count': cpu_count,
    }


def get_recommended_level() -> PerformanceLevel:
    """–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    env = detect_environment()
    
    if not env['has_gpu']:
        # CPU only
        if env['cpu_count'] >= 8:
            return PerformanceLevel.LOW
        else:
            return PerformanceLevel.MINIMAL
    
    # GPU –¥–æ—Å—Ç—É–ø–µ–Ω
    gpu_memory = env['gpu_memory_gb']
    
    if gpu_memory >= 20:  # A100, V100
        return PerformanceLevel.ULTRA
    elif gpu_memory >= 14:  # T4, RTX 3080
        return PerformanceLevel.HIGH
    elif gpu_memory >= 8:  # GTX 1080, RTX 2060
        return PerformanceLevel.MEDIUM
    else:
        return PerformanceLevel.LOW


def get_config(level: Optional[PerformanceLevel] = None) -> PerformanceConfig:
    """
    –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
    –ï—Å–ª–∏ level=None, –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    """
    if level is None:
        level = get_recommended_level()
    
    config = PERFORMANCE_PRESETS[level]
    
    # –ê–≤—Ç–æ–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ GPU –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    env = detect_environment()
    if config.use_gpu and not env['has_gpu']:
        config.use_gpu = False
        config.fp16 = False
    
    return config


def print_environment_info():
    """–í—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–∫—Ä—É–∂–µ–Ω–∏–∏"""
    env = detect_environment()
    recommended = get_recommended_level()
    
    print("="*70)
    print("üñ•Ô∏è  –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û–ë –û–ö–†–£–ñ–ï–ù–ò–ò")
    print("="*70)
    
    print(f"\nüìç –°—Ä–µ–¥–∞: {'Google Colab' if env['is_colab'] else '–õ–æ–∫–∞–ª—å–Ω–∞—è'}")
    print(f"üî¢ CPU —è–¥–µ—Ä: {env['cpu_count']}")
    
    if env['has_gpu']:
        print(f"‚úÖ GPU: {env['gpu_name']}")
        print(f"üíæ VRAM: {env['gpu_memory_gb']:.1f} GB")
    else:
        print("‚ùå GPU: –ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
    
    print(f"\n‚≠ê –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å: {recommended} ({recommended.name})")
    
    print("\nüìä –î–û–°–¢–£–ü–ù–´–ï –£–†–û–í–ù–ò:")
    print("-"*70)
    
    for level in PerformanceLevel:
        config = PERFORMANCE_PRESETS[level]
        gpu_req = "üéÆ GPU" if config.use_gpu else "üñ•Ô∏è  CPU"
        
        print(f"{level}. {level.name:10} - {gpu_req} - "
              f"Whisper:{config.whisper_model:6} - "
              f"YOLO:{config.yolo_model} - "
              f"AI:{'‚úÖ' if config.enable_ai_analysis else '‚ùå'}")
    
    print("="*70)


if __name__ == "__main__":
    print_environment_info()
    
    print("\nüß™ –¢–ï–°–¢ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ô:")
    print("-"*70)
    
    for level in PerformanceLevel:
        config = get_config(level)
        print(f"\nLevel {level} ({level.name}):")
        print(f"  Whisper: {config.whisper_model}")
        print(f"  YOLO: {config.yolo_model}")
        print(f"  GPU: {config.use_gpu}")
        print(f"  AI Analysis: {config.enable_ai_analysis}")
